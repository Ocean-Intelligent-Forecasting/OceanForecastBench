# Copyright (c) Microsoft Corporation.
# Licensed under the MIT license.

import math
import os
import random

import numpy as np
import torch
import logging
from torch.utils.data import IterableDataset

FORMAT = '[%(levelname)s: %(filename)s:%(lineno)4d]: %(message)s'
logging.basicConfig(level=logging.INFO, format=FORMAT,filename='../train.log',filemode='a')
logger = logging.getLogger(__name__)

class NpyReader(IterableDataset): #为每个进程分配需要处理的数据
    def __init__(
        self,
        nodes,
        file_list,
        start_idx,
        end_idx,
        variables, #输入变量
        out_variables,
        var_map,
        predict_range,
        shuffle: bool = False,
        multi_dataset_training=True,
    ) -> None:
        super().__init__()
        start_idx = int(start_idx * len(file_list))
        end_idx = int(end_idx * len(file_list))
        file_list = file_list[start_idx:end_idx]
        self.file_list = [f for f in file_list if "climatology" not in f]
        self.variables = variables
        self.out_variables = out_variables if out_variables is not None else variables
        self.predict_range = predict_range
        self.shuffle = shuffle
        self.multi_dataset_training = multi_dataset_training
        self.nodes = nodes
        self.var_map = var_map
        self.length = end_idx - start_idx

    def __iter__(self):
        # 是否打乱数据
        if self.shuffle:
            random.shuffle(self.file_list)
        worker_info = torch.utils.data.get_worker_info()
        # print('worker_info:', worker_info)
        if worker_info is None:
            iter_start = 0
            iter_end = len(self.file_list)-self.predict_range
        else:
            if not torch.distributed.is_initialized():
                rank = 0
                world_size = 1
            else:
                rank = torch.distributed.get_rank()
                world_size = torch.distributed.get_world_size()
            # print('rank:', rank)
            # print('world_size:', world_size)
            
            num_workers_per_ddp = worker_info.num_workers 
            
            if self.multi_dataset_training:
                #num_nodes = int(os.environ.get("NODES", None))
                num_nodes = self.nodes
                num_gpus_per_node = int(world_size / num_nodes)
                num_shards = num_workers_per_ddp * num_gpus_per_node
                rank = rank % num_gpus_per_node
                
            else:
                num_shards = num_workers_per_ddp * world_size
            per_worker = int(math.floor(len(self.file_list) / float(num_shards)))
            
            worker_id = rank * num_workers_per_ddp + worker_info.id
            #logger.info("worker_id:{}".format(worker_id))
            iter_start = worker_id * per_worker
            iter_end = min(iter_start + per_worker,len(self.file_list)-self.predict_range)

        for idx in range(iter_start, iter_end):
            path_x = self.file_list[idx]
            data_x = np.load(path_x)
            # print('85:',data_x.shape)
            # logger.info("data_shape:{}".format(data_x.shape))
            path_y = self.file_list[idx+self.predict_range]
            data_y = np.load(path_y)
            index_in = []
            index_out = []
            for var in self.variables:
                index_in.append(self.var_map[var])
            data_x = data_x[:,index_in,:,:]
            # data_x[:,0,:,:] = data_x[:,0,:,:]-273.15 #把sst这个要素换算成摄氏度
            for var in self.out_variables:
                index_out.append(self.var_map[var])
            data_y = data_y[:,index_out,:,:]
            # data_y[:,0,:,:] = data_y[:,0,:,:]-273.15 #把sst这个要素换算成摄氏度
            
            #yield {k: data_x[k] for k in self.variables}, {k: data_y[k] for k in self.out_variables},self.variables, self.out_variables
            yield data_x, data_y, self.variables, self.out_variables


class Forecast(IterableDataset):
    def __init__(
        self, dataset: NpyReader, max_predict_range: int = 6, random_lead_time: bool = False, hrs_each_step: int = 1
    ) -> None:
        super().__init__()
        self.dataset = dataset
        self.max_predict_range = max_predict_range
        self.random_lead_time = random_lead_time
        self.hrs_each_step = hrs_each_step

    def __iter__(self):
        for data_x,data_y, variables, out_variables in self.dataset:
           
            inputs = torch.from_numpy(data_x)
            outputs = torch.from_numpy(data_y)
            if self.random_lead_time:
                predict_ranges = torch.randint(low=1, high=self.max_predict_range, size=(inputs.shape[0],))
            else:
                predict_ranges = torch.ones(inputs.shape[0]).to(torch.long) * self.max_predict_range
            lead_times = self.hrs_each_step * predict_ranges / 100
            lead_times = lead_times.to(inputs.dtype)
            # output_ids = torch.arange(inputs.shape[0]) + predict_ranges #需要预测的index
            # outputs = y[output_ids]
            #print('dataset.py_129:',inputs.shape,outputs.shape)
            yield inputs, outputs, lead_times, variables, out_variables


class IndividualForecastDataIter(IterableDataset):
    def __init__(self, dataset, transforms: torch.nn.Module, output_transforms: torch.nn.Module, region_info = None):
        super().__init__()
        self.dataset = dataset
        self.transforms = transforms
        self.output_transforms = output_transforms
        self.region_info = region_info

    def __iter__(self):
        for (inp, out, lead_times, variables, out_variables) in self.dataset:
            assert inp.shape[0] == out.shape[0]
            for i in range(inp.shape[0]):
                if self.region_info is not None:
                    yield self.transforms(inp[i]), self.output_transforms(out[i]), lead_times[i], variables, out_variables, self.region_info
                else: #对数据做归一化操作
                    # print(inp[i].shape,out[i].shape)
                    inp[i][np.isnan(inp[i]).bool()] = -32767
                    mask_inp=inp[i]<-30000
                    x = self.transforms(inp[i])
                    x[mask_inp]=0 #陆地部分填0
                    out[i][np.isnan(out[i]).bool()] = -32767
                    mask_out = out[i]<-30000
                    y = self.output_transforms(out[i])
                    y[mask_out]=0

                    mask = out[i]>-30000 #海洋为1，陆地为0
                    # mask_thetao = inp[i]>-30000
                    # mask[2,:,:] = mask[2,:,:] & mask_thetao[3,:,:] #取thetao_0和sst掩码的交集
                    yield x, y, lead_times[i], variables, out_variables,mask


class ShuffleIterableDataset(IterableDataset):
    def __init__(self, dataset, buffer_size: int) -> None:
        super().__init__()
        assert buffer_size > 0
        self.dataset = dataset
        self.buffer_size = buffer_size

    def __iter__(self):
        buf = []
        for x in self.dataset:
            if len(buf) == self.buffer_size:
                idx = random.randint(0, self.buffer_size - 1)
                yield buf[idx]
                buf[idx] = x
            else:
                buf.append(x)
        random.shuffle(buf)
        while buf:
            yield buf.pop()
